{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ef9fd6c",
   "metadata": {},
   "source": [
    "## TextCNN 文本分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5110ab50",
   "metadata": {},
   "source": [
    "### 1 data reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "776e8cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 12500/12500 [00:01<00:00, 6426.72it/s]\n",
      "100%|███████████████████████████████████| 12500/12500 [00:01<00:00, 6490.82it/s]\n",
      "100%|███████████████████████████████████| 12500/12500 [00:01<00:00, 6662.28it/s]\n",
      "100%|███████████████████████████████████| 12500/12500 [00:01<00:00, 7567.94it/s]\n"
     ]
    }
   ],
   "source": [
    "# library related packages\n",
    "import collections\n",
    "import os\n",
    "import random\n",
    "import tarfile\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchtext.vocab as Vocab\n",
    "import torch.utils.data as Data\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "from pandas import DataFrame\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DATA_ROOT = \"/Users/hongcan/Documents/HKU STAT/STAT7008\"  # change the value to the folder directory in your computer\n",
    "fname = os.path.join(DATA_ROOT, \"aclImdb_v1.tar.gz\")\n",
    "if not os.path.exists(os.path.join(DATA_ROOT, \"aclImdb\")):\n",
    "    print(\"从压缩包解压...\")\n",
    "    with tarfile.open(fname, 'r') as f: \n",
    "        f.extractall(DATA_ROOT)\n",
    "        \n",
    "# load the data\n",
    "def read_imdb_train(folder='train', data_root=\"/Users/hongcan/Documents/HKU STAT/STAT7008/aclImdb\"):\n",
    "    data = []\n",
    "    for label in ['pos', 'neg']:\n",
    "        folder_name = os.path.join(data_root, folder, label)\n",
    "        for file in tqdm(os.listdir(folder_name)):\n",
    "            with open(os.path.join(folder_name, file), 'rb') as f:\n",
    "                review = f.read().decode('utf-8').replace('\\n','').lower()\n",
    "                data.append([review, 1 if label == 'pos' else 0])\n",
    "    random.shuffle(data)\n",
    "    return data\n",
    "\n",
    "def read_imdb_test(folder='test', data_root=\"/Users/hongcan/Documents/HKU STAT/STAT7008/aclImdb\"):\n",
    "    data = []\n",
    "    for label in ['pos', 'neg']:\n",
    "        folder_name = os.path.join(data_root, folder, label)\n",
    "        for file in tqdm(os.listdir(folder_name)):\n",
    "            with open(os.path.join(folder_name, file), 'rb') as f:\n",
    "                review = f.read().decode('utf-8').replace('\\n','').lower()\n",
    "                data.append([review, 1 if label == 'pos' else 0])\n",
    "    random.shuffle(data)\n",
    "    return data\n",
    "train_data, test_data = read_imdb_train('train'), read_imdb_test('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07f0e6eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"first, let's all agree that lorenzo lamas could never be considered a skilled actor, barely even decent, sometimes just plain lousy. however, in this piece of @*!^ called snakeeater, the film industry as a whole sank.<br /><br />first, let's start with the plot. a vietnam vet named jack kelly, aka soldier (who is supposed to be as tough as a strap of leather and then some, which you can believe when he shoves a palate of nails through 2 guys' feet and pins them to the floor), gets word that his family has been killed and his sister kidnapped. therefore he goes on a solo mission to save his sister. had some potential, but still pretty thin to begin with.<br /><br />now, the acting. being an actor myself, i am qualified to say that this was some of the worst acting in the history of the art!!!!! lamas is, well, himself. the jackasses playing the clampets/deliverance rejects should be strung up and shot for their so-called performances which are insulting to actors everywhere, especially talented ones who never get their big break!<br /><br />finally, the action. the gunfighting is so-so at best, and the fist-fighting is deplorable. i've seen more real-looking fights at the renaissance festival (and those were pretty fake-looking)!<br /><br />readers, listen to me: avoid this piece of caca at all costs! if it were the only film in existence, you still would want to avoid it! for the sake of your brain-cell count, do not watch this thing!\",\n",
       " 0]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0489bea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"i'm glad i never watched this show when it came out.<br /><br />i just wondered why it lasted 4 years. it reminds me of the terrible 80's with fake people, fake clothes, and fake music. how did i ever survive growing up in this era? <br /><br />the acting in the majority of episodes i have watched are forced. this makes for very boring shows. the plot lines are not very interesting as the old twilight zone shows. the old show inspired the imagination and made one look forward to the next show. <br /><br />stick with the old twilight zone shows and spare yourself the pain of watching garbage.\",\n",
       " 0]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364eb954",
   "metadata": {},
   "source": [
    "### 2 data cleaning - tokenization, extract flag, standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2459fa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenized_imdb(data):\n",
    "    \"\"\"\n",
    "     data: list of [string, label]，\n",
    "     \"\"\"\n",
    "    def tokenizer(text):\n",
    "        return [tok.lower() for tok in text.split(' ')]\n",
    "    return [tokenizer(review) for review, _ in data] \n",
    "\n",
    "\n",
    "def get_vocab_imdb(data):\n",
    "    tokenized_data = get_tokenized_imdb(data)\n",
    "    counter = collections.Counter([tk for st in tokenized_data for tk in st])\n",
    "    return Vocab.Vocab(counter,None, 5)   # max_size=None,min_freq=5\n",
    "vocab = get_vocab_imdb(train_data)        # put the vacabulary into a dictionary and remove words that occur less than 5 times in the dictionary\n",
    "\n",
    "def preprocess_imdb(data, vocab):\n",
    "    max_l = 500                           # standardize the length of each sentences into 500\n",
    "    def pad(x):\n",
    "        return x[:max_l] if len(x) > max_l else x + [0] * (max_l - len(x))\n",
    "    tokenized_data = get_tokenized_imdb(data)\n",
    "    features = torch.tensor([pad([vocab.stoi[word] for word in words]) for words in tokenized_data])\n",
    "    labels = torch.tensor([score for _, score in data])\n",
    "    return features, label                # feature stands for the text vectors, and labels stand for the sentiment label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68aaaad5",
   "metadata": {},
   "source": [
    "### 3 construct initial Text CNN model - encapsulation （parameter shows batch_size, kernal_size, num_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "807f8f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalMaxPool1d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GlobalMaxPool1d, self).__init__()\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, channel, seq_len)\n",
    "        # return shape: (batch_size, channel, 1)\n",
    "        return F.max_pool1d(x, kernel_size=x.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb3056e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data encapsulation (parameter 1:batchsize）\n",
    "batch_size = 64 \n",
    "train_set = Data.TensorDataset(*preprocess_imdb(train_data, vocab))\n",
    "test_set = Data.TensorDataset(*preprocess_imdb(test_data, vocab))\n",
    "train_iter = Data.DataLoader(train_set, batch_size, shuffle=True)\n",
    "test_iter = Data.DataLoader(test_set, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "416788a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X torch.Size([64, 500]) y torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_iter:\n",
    "    print('X', X.shape, 'y', y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86d4a22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(nn.Module):\n",
    "    def __init__(self, vocab, embed_size, kernel_sizes, num_channels):\n",
    "        super(TextCNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(len(vocab), embed_size)\n",
    "        self.constant_embedding = nn.Embedding(len(vocab), embed_size)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.decoder = nn.Linear(sum(num_channels), 2)\n",
    "        self.pool = GlobalMaxPool1d()\n",
    "        self.convs = nn.ModuleList()\n",
    "        for c, k in zip(num_channels, kernel_sizes):\n",
    "            self.convs.append(nn.Conv1d(in_channels = 2*embed_size, out_channels = c, kernel_size = k))\n",
    "    def forward(self, inputs):\n",
    "        embeddings = torch.cat((self.embedding(inputs),\n",
    "        self.constant_embedding(inputs)), dim=2) # (batch, seq_len, 2*embed_size)\n",
    "        embeddings = embeddings.permute(0, 2, 1)\n",
    "        encoding = torch.cat([self.pool(F.relu(conv(embeddings))).squeeze(-1) for conv in self.convs], dim=1)\n",
    "        outputs = self.decoder(self.dropout(encoding))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5069fb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ————————————————————————————————parameter tuning————————————————————————————————————\n",
    "embed_size,  kernel_sizes, nums_channels = 100, [3, 4, 5], [100, 100, 100]\n",
    "net = TextCNN(vocab, embed_size, kernel_sizes, nums_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f88897",
   "metadata": {},
   "source": [
    "### 4 Embedding using glove_100.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58a7a809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_embedding(words, pretrained_vocab):\n",
    "    embed = torch.zeros(len(words), pretrained_vocab.vectors[0].shape[0]) # 初始化为0\n",
    "    oov_count = 0 # out of vocabulary\n",
    "    for i, word in enumerate(words):\n",
    "        try:\n",
    "            idx = pretrained_vocab.stoi[word]\n",
    "            embed[i, :] = pretrained_vocab.vectors[idx]\n",
    "        except KeyError:\n",
    "            oov_count += 0\n",
    "    if oov_count > 0:\n",
    "        print(\"There are %d oov words.\")\n",
    "    return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9db75038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the file glove100.txt\n",
    "glove_vocab = Vocab.GloVe(name='6B', dim=100, cache=os.path.join(DATA_ROOT, \"glove\"))\n",
    "net.embedding.weight.data.copy_(load_pretrained_embedding(vocab.itos, glove_vocab))\n",
    "net.constant_embedding.weight.data.copy_(load_pretrained_embedding(vocab.itos, glove_vocab))\n",
    "net.constant_embedding.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836b6bae",
   "metadata": {},
   "source": [
    "### 5 training (optimization) and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "398b4662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define evaluation parameter\n",
    "def evaluate_accuracy(data_iter, net, device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')):\n",
    "    acc_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(net, torch.nn.Module):\n",
    "                net.eval() \n",
    "                acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
    "                net.train() \n",
    "            else:\n",
    "                if ('is_training' in net.__code__.co_varnames):\n",
    "                    acc_sum += (net(X, is_training = False).argmax(dim=1) == y).float().sum().item()\n",
    "                else:\n",
    "                    acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()\n",
    "            n += y.shape[0]\n",
    "    return acc_sum / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "113b6507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_iter, test_iter, net, loss, optimizer, device, num_epochs):\n",
    "    result = []\n",
    "    for epoch in range(num_epochs):\n",
    "        train_acc_sum, sum_l, start, n, batch_count = 0.0, 0.0, time.time(), 0, 0\n",
    "        for X, y in train_iter:\n",
    "            out = net(X)\n",
    "            l = loss(out,y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            sum_l += l.cpu().item()\n",
    "            n += y.shape[0]\n",
    "            batch_count += 1\n",
    "            train_acc_sum += (out.argmax(dim=1) == y).float().sum().cpu().item()\n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        print('epoch %d, loss %.4f, train_acc %.3f, test acc %.3f, time %.1f sec'\n",
    "             % (epoch + 1, sum_l / batch_count, train_acc_sum / n, test_acc, time.time() - start ))\n",
    "        result.append('epoch %d, loss %.4f, train_acc %.3f, test acc %.3f, time %.1f sec'\n",
    "             % (epoch + 1, sum_l / batch_count, train_acc_sum / n, test_acc, time.time() - start ))\n",
    "    return (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f49c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num, num_epochs = 0.001, 5, 15      # num_epochs represeent the number of training epoches\n",
    "optimizer = torch.optim.Adam(filter(lambda p:p.requires_grad, net.parameters()), lr=lr)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "train(train_iter, test_iter, net, loss, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f115eef6",
   "metadata": {},
   "source": [
    "### 6 prediction application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2274c47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(net, vocab, sentence):\n",
    "    device = list(net.parameters())[0].device\n",
    "    sentence = torch.tensor([vocab.stoi[word] for word in sentence], device=device)\n",
    "    label = torch.argmax(net(sentence.view((1, -1))), dim=1)\n",
    "    return 'positive' if label.item() == 1 else 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fba8c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "        return [tok.lower() for tok in text.split(' ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e86b9b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment = \"How much sympathy can we muster for a wealthy, celebrated filmmaker on holiday? It’s hard not to roll your eyes when Silverio says things like, “Success has been my biggest failure\"\n",
    "predict_sentiment(net, vocab, tokenizer(comment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3ae8a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment = \"Titanic＂ is a poem. Ten years ago, it swept the world, won 11 Oscars large giant system to passion, dreams, sadness, couage and momentum rainbow scene to the differences between Jack and Rose secular love of life and death, as well as disaster flashed out of glorious epic of human nature, and warmth touched countless heart and become a rich humanistic atmosphere overflowing disaster film classic. Wandering artist Jack Rose and beautiful, in the luxurious Titanic encounter love, but the unexpected tragedy, the Titanic collided with the tip of the fracture, jack will be Rose onto a floating plank, himself immersed in Ice in frozen to death. In addition to creative the theme song ＂ my heart forever,＂ Jack and Rose standing on the bow railing the wind to fly, as well as their time and survived,etc ink rendering, the film there is a lens language , depiction of a critical the calm , serene and elegant, compared to the comfusion, panic and ugly. Perhaps, fortume or misfortune, sadness and happiness, are forever time in reincarnation, life should be realized is the this seene gaze of God？\"\n",
    "predict_sentiment(net, vocab, tokenizer(comment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "88df6b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment = \"This movie is not my fav.\"\n",
    "predict_sentiment(net, vocab, tokenizer(comment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9d16def7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment = \"We can not say this movie is good.\"\n",
    "predict_sentiment(net, vocab, tokenizer(comment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bbc58587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment = \"We can not say this movie is boring.\"\n",
    "predict_sentiment(net, vocab, tokenizer(comment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "34e97403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment = \"We can not say this movie is not good.\"\n",
    "predict_sentiment(net, vocab, tokenizer(comment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b7460606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment = \"We can not say this movie is not boring.\"\n",
    "predict_sentiment(net, vocab, tokenizer(comment))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ae1b2d",
   "metadata": {},
   "source": [
    "### 7 parameter tunning and result showing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88655af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 result with different epoches\n",
    "\n",
    "# 2 different kernel sizes and channel numbers with the same kernel numbers\n",
    "# 2.1 【3，4，5】【100，100，100】 small kernel sizes\n",
    "# 2.2 【8，9，10】【100，100，100】 big kernel sizes\n",
    "# 2.3 【3，5，8】【100，100，100】 medium kernel sizes\n",
    "# 2.4 【3，5，8】【80，100，120】 different channel number with different kernel sizes\n",
    "\n",
    "# 3 different kernel numbers\n",
    "# 3.1 【3，5】【100，100】 two kernels (compared with 2.1)\n",
    "# 3.2 【2，3，4，5】【100，100，100，100】 four kernels (compared with 2.1)\n",
    "# 3.3 【3，5，7，9】【100，100，100，100】 four kernels with big spans (compared with 2.1 and 2.2)\n",
    "\n",
    "# 4 different batch_size\n",
    "# 4.1 64\n",
    "# 4.2 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57c8061f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter - batch_size\n",
    "random.seed(101)\n",
    "\n",
    "batch_size = 64 \n",
    "\n",
    "train_set = Data.TensorDataset(*preprocess_imdb(train_data, vocab))\n",
    "test_set = Data.TensorDataset(*preprocess_imdb(test_data, vocab))\n",
    "train_iter = Data.DataLoader(train_set, batch_size, shuffle=True)\n",
    "test_iter = Data.DataLoader(test_set, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba17646f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.4802, train_acc 0.764, test acc 0.844, time 618.5 sec\n",
      "epoch 2, loss 0.3238, train_acc 0.862, test acc 0.864, time 243.3 sec\n",
      "epoch 3, loss 0.2111, train_acc 0.916, test acc 0.876, time 245.4 sec\n",
      "epoch 4, loss 0.1228, train_acc 0.956, test acc 0.875, time 245.8 sec\n",
      "epoch 5, loss 0.0656, train_acc 0.978, test acc 0.874, time 249.3 sec\n"
     ]
    }
   ],
   "source": [
    "# 2.1\n",
    "embed_size,  kernel_sizes, nums_channels = 100, [3, 4, 5], [100, 100, 100]\n",
    "\n",
    "net = TextCNN(vocab, embed_size, kernel_sizes, nums_channels)\n",
    "\n",
    "glove_vocab = Vocab.GloVe(name='6B', dim=100, cache=os.path.join(DATA_ROOT, \"glove\"))\n",
    "net.embedding.weight.data.copy_(load_pretrained_embedding(vocab.itos, glove_vocab))\n",
    "net.constant_embedding.weight.data.copy_(load_pretrained_embedding(vocab.itos, glove_vocab))\n",
    "net.constant_embedding.weight.requires_grad = False\n",
    "\n",
    "lr, num, num_epochs = 0.001, 5, 5 \n",
    "optimizer = torch.optim.Adam(filter(lambda p:p.requires_grad, net.parameters()), lr=lr)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "result = train(train_iter, test_iter, net, loss, optimizer, device, num_epochs)\n",
    "result = DataFrame(result)\n",
    "result.to_excel(\"/Users/hongcan/Documents/HKU STAT/STAT7008/batchsize128.xlsx\", sheet_name='2.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3218fabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.4961, train_acc 0.751, test acc 0.851, time 479.0 sec\n",
      "epoch 2, loss 0.3124, train_acc 0.869, test acc 0.861, time 506.4 sec\n",
      "epoch 3, loss 0.1963, train_acc 0.924, test acc 0.883, time 516.6 sec\n",
      "epoch 4, loss 0.1154, train_acc 0.957, test acc 0.879, time 796.1 sec\n",
      "epoch 5, loss 0.0657, train_acc 0.976, test acc 0.879, time 648.6 sec\n"
     ]
    }
   ],
   "source": [
    "# 2.2\n",
    "embed_size,  kernel_sizes, nums_channels = 100, [8, 9, 10], [100, 100, 100]\n",
    "\n",
    "net = TextCNN(vocab, embed_size, kernel_sizes, nums_channels)\n",
    "\n",
    "glove_vocab = Vocab.GloVe(name='6B', dim=100, cache=os.path.join(DATA_ROOT, \"glove\"))\n",
    "net.embedding.weight.data.copy_(load_pretrained_embedding(vocab.itos, glove_vocab))\n",
    "net.constant_embedding.weight.data.copy_(load_pretrained_embedding(vocab.itos, glove_vocab))\n",
    "net.constant_embedding.weight.requires_grad = False\n",
    "\n",
    "lr, num, num_epochs = 0.001, 5, 5 \n",
    "optimizer = torch.optim.Adam(filter(lambda p:p.requires_grad, net.parameters()), lr=lr)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "result = train(train_iter, test_iter, net, loss, optimizer, device, num_epochs)\n",
    "result = DataFrame(result)\n",
    "#result.to_excel(\"/Users/hongcan/Documents/HKU STAT/STAT7008/batchsize128.xlsx\", sheet_name='2.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdabf4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3\n",
    "embed_size,  kernel_sizes, nums_channels = 100, [3, 5, 8], [100, 100, 100]\n",
    "\n",
    "net = TextCNN(vocab, embed_size, kernel_sizes, nums_channels)\n",
    "\n",
    "glove_vocab = Vocab.GloVe(name='6B', dim=100, cache=os.path.join(DATA_ROOT, \"glove\"))\n",
    "net.embedding.weight.data.copy_(load_pretrained_embedding(vocab.itos, glove_vocab))\n",
    "net.constant_embedding.weight.data.copy_(load_pretrained_embedding(vocab.itos, glove_vocab))\n",
    "net.constant_embedding.weight.requires_grad = False\n",
    "\n",
    "lr, num, num_epochs = 0.001, 5, 15 \n",
    "optimizer = torch.optim.Adam(filter(lambda p:p.requires_grad, net.parameters()), lr=lr)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "result = train(train_iter, test_iter, net, loss, optimizer, device, num_epochs)\n",
    "result = DataFrame(result)\n",
    "result.to_excel(\"/Users/hongcan/Documents/HKU STAT/STAT7008/batchsize128.xlsx\", sheet_name='2.3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14e86bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4\n",
    "embed_size,  kernel_sizes, nums_channels = 100, [3, 5, 8], [80, 100, 120]\n",
    "\n",
    "net = TextCNN(vocab, embed_size, kernel_sizes, nums_channels)\n",
    "\n",
    "glove_vocab = Vocab.GloVe(name='6B', dim=100, cache=os.path.join(DATA_ROOT, \"glove\"))\n",
    "net.embedding.weight.data.copy_(load_pretrained_embedding(vocab.itos, glove_vocab))\n",
    "net.constant_embedding.weight.data.copy_(load_pretrained_embedding(vocab.itos, glove_vocab))\n",
    "net.constant_embedding.weight.requires_grad = False\n",
    "\n",
    "lr, num, num_epochs = 0.001, 5, 15 \n",
    "optimizer = torch.optim.Adam(filter(lambda p:p.requires_grad, net.parameters()), lr=lr)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "result = train(train_iter, test_iter, net, loss, optimizer, device, num_epochs)\n",
    "result = DataFrame(result)\n",
    "result.to_excel(\"/Users/hongcan/Documents/HKU STAT/STAT7008/batchsize128.xlsx\", sheet_name='2.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a65b643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1\n",
    "embed_size,  kernel_sizes, nums_channels = 100, [3, 5], [100, 100]\n",
    "\n",
    "net = TextCNN(vocab, embed_size, kernel_sizes, nums_channels)\n",
    "\n",
    "glove_vocab = Vocab.GloVe(name='6B', dim=100, cache=os.path.join(DATA_ROOT, \"glove\"))\n",
    "net.embedding.weight.data.copy_(load_pretrained_embedding(vocab.itos, glove_vocab))\n",
    "net.constant_embedding.weight.data.copy_(load_pretrained_embedding(vocab.itos, glove_vocab))\n",
    "net.constant_embedding.weight.requires_grad = False\n",
    "\n",
    "lr, num, num_epochs = 0.001, 5, 15 \n",
    "optimizer = torch.optim.Adam(filter(lambda p:p.requires_grad, net.parameters()), lr=lr)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "result = train(train_iter, test_iter, net, loss, optimizer, device, num_epochs)\n",
    "result = DataFrame(result)\n",
    "result.to_excel(\"/Users/hongcan/Documents/HKU STAT/STAT7008/batchsize128.xlsx\", sheet_name='3.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fa38fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2\n",
    "embed_size,  kernel_sizes, nums_channels = 100, [2, 3, 4, 5], [100, 100, 100, 100]\n",
    "\n",
    "net = TextCNN(vocab, embed_size, kernel_sizes, nums_channels)\n",
    "\n",
    "glove_vocab = Vocab.GloVe(name='6B', dim=100, cache=os.path.join(DATA_ROOT, \"glove\"))\n",
    "net.embedding.weight.data.copy_(load_pretrained_embedding(vocab.itos, glove_vocab))\n",
    "net.constant_embedding.weight.data.copy_(load_pretrained_embedding(vocab.itos, glove_vocab))\n",
    "net.constant_embedding.weight.requires_grad = False\n",
    "\n",
    "lr, num, num_epochs = 0.001, 5, 15 \n",
    "optimizer = torch.optim.Adam(filter(lambda p:p.requires_grad, net.parameters()), lr=lr)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "result = train(train_iter, test_iter, net, loss, optimizer, device, num_epochs)\n",
    "result = DataFrame(result)\n",
    "result.to_excel(\"/Users/hongcan/Documents/HKU STAT/STAT7008/batchsize128.xlsx\", sheet_name='3.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7c360b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3\n",
    "embed_size,  kernel_sizes, nums_channels = 100, [3, 5, 7, 9], [100, 100, 100, 100]\n",
    "\n",
    "net = TextCNN(vocab, embed_size, kernel_sizes, nums_channels)\n",
    "\n",
    "glove_vocab = Vocab.GloVe(name='6B', dim=100, cache=os.path.join(DATA_ROOT, \"glove\"))\n",
    "net.embedding.weight.data.copy_(load_pretrained_embedding(vocab.itos, glove_vocab))\n",
    "net.constant_embedding.weight.data.copy_(load_pretrained_embedding(vocab.itos, glove_vocab))\n",
    "net.constant_embedding.weight.requires_grad = False\n",
    "\n",
    "lr, num, num_epochs = 0.001, 5, 15 \n",
    "optimizer = torch.optim.Adam(filter(lambda p:p.requires_grad, net.parameters()), lr=lr)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "result = train(train_iter, test_iter, net, loss, optimizer, device, num_epochs)\n",
    "result = DataFrame(result)\n",
    "result.to_excel(\"/Users/hongcan/Documents/HKU STAT/STAT7008/batchsize128.xlsx\", sheet_name='3.3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
